{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7d3fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Router/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbde61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS_JSON_PATH = \"/home/ubuntu/Router/data/tools_v1.json\"\n",
    "TOOLS_DESCRIPTION_JSON_PATH = \"/home/ubuntu/Router/data/tool_descriptions_v1.json\"\n",
    "\n",
    "tools_description_map = {}\n",
    "with open(TOOLS_DESCRIPTION_JSON_PATH, \"r\") as f:\n",
    "    tools_description_map = json.load(f)\n",
    "\n",
    "with open(TOOLS_JSON_PATH, \"r\") as f:\n",
    "    tools = json.load(f)\n",
    "\n",
    "tools_map = []\n",
    "tools_to_integration_map = {}\n",
    "for category, tools in tools.items():\n",
    "    for tool in tools:\n",
    "        tools_map.append(tool[\"name\"])\n",
    "        tools_to_integration_map[tool[\"name\"]] = category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "247f0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_descriptions_to_tool_name = {}\n",
    "for tool_name, tool_description in tools_description_map.items():\n",
    "    tool_descriptions_to_tool_name[tool_description] = tool_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60278ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "466000it [00:00, 575594.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_data_files = glob.glob(\"../data/sft_data_v1/*.json\")\n",
    "data_df = None\n",
    "for i, file in enumerate(all_data_files):\n",
    "    if data_df is None:\n",
    "        data_df = pd.read_json(file)\n",
    "    else:\n",
    "        data_df = pd.concat([data_df, pd.read_json(file)])\n",
    "\n",
    "assert data_df is not None\n",
    "\n",
    "tool_set = set()\n",
    "for i, tools_required in tqdm(enumerate(data_df['tools_required'].to_list())):\n",
    "    tool_list = []\n",
    "    for tool in tools_required:\n",
    "        tool_name = tool.split('-')[0].split(' ')[0]\n",
    "        # data_df.loc[i, tool_name] = True\n",
    "        tool_set.add(tool_name)\n",
    "        # tool_list.append(tool_name)\n",
    "    # data_df.loc[i, 'tools_required_list'] = tool_list\n",
    "\n",
    "tool_set = list(tool_set)\n",
    "print(len(tool_set))\n",
    "for tool_name in tool_set:\n",
    "    data_df[tool_name] = data_df['tools_required'].apply(lambda x: tool_name in x)\n",
    "data_df.to_pickle(\"../data/data_df_v1.pkl\")\n",
    "# data_df.to_pickle(\"../data/sft_data/data_df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9dc89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['direct_reply_to_user', 'create_event', 'update_event', 'capture_screenshot', 'update_note', 'search_events', 'send_message_on_slack', 'search_location', 'trash_file', 'delete_event', 'unachievable_task', 'create_reminder', 'search_notes', 'update_reminder', 'unachievable', 'search_messages', 'update_file', 'open_url', 'create_file', 'start_call', 'find_stock_symbol', 'send_email', 'play_song', 'get_directions', 'Unachievable', 'search_inbox', 'send_message_on_messages', 'search_library', 'get_weather', 'create_note']\n"
     ]
    }
   ],
   "source": [
    "print(tool_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bedf65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle(\"../data/data_df_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33122f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813448\n"
     ]
    }
   ],
   "source": [
    "# make pairs for each row\n",
    "positive_pairs = []\n",
    "for tool_name in tool_set:\n",
    "    filtered_df = data_df[data_df[tool_name] == True]\n",
    "    if tool_name not in tools_to_integration_map:\n",
    "        continue\n",
    "    integration_name = tools_to_integration_map[tool_name]\n",
    "    query_list = filtered_df['query'].tolist()\n",
    "    for query in query_list:\n",
    "        positive_pairs.append((query, integration_name))\n",
    "\n",
    "print(len(positive_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cee05f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "positive_pairs_dict = []\n",
    "for i in range(len(positive_pairs)):\n",
    "    positive_pairs_dict.append({\n",
    "        \"text1\": positive_pairs[i][0],\n",
    "        \"text2\": positive_pairs[i][1]\n",
    "    })\n",
    "\n",
    "with open(\"../data/positive_pairs_v1.json\", \"w\") as f:\n",
    "    json.dump(positive_pairs_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21f2f1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658892 73211 81345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 658892/658892 [00:02<00:00, 251611.51 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 73211/73211 [00:00<00:00, 243926.60 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 81345/81345 [00:00<00:00, 257523.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets import DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_list(positive_pairs_dict)\n",
    "dataset.shuffle()\n",
    "\n",
    "dataset_train_test = dataset.train_test_split(test_size=0.1)\n",
    "dataset_test = dataset_train_test['test']\n",
    "dataset_train_val = dataset_train_test['train'].train_test_split(test_size=0.1)\n",
    "dataset_train = dataset_train_val['train']\n",
    "dataset_val = dataset_train_val['test']\n",
    "\n",
    "print(len(dataset_train), len(dataset_val), len(dataset_test))\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": dataset_train,\n",
    "    \"val\": dataset_val,\n",
    "    \"test\": dataset_test\n",
    "})\n",
    "\n",
    "dataset_dict.save_to_disk(\"../data/positive_pairs_train_val_test_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "405d13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_val_test = load_from_disk(\"../data/positive_pairs_train_val_test_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c44792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tool_descriptions =list(tools_description_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c477057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36877 36334\n",
      "40698 40647\n"
     ]
    }
   ],
   "source": [
    "queries = []\n",
    "tool_descriptions = []\n",
    "for i in range(len(dataset_train_val_test['val'])):\n",
    "    queries.append(dataset_train_val_test['val'][i]['text1'])\n",
    "    tool_descriptions.append(dataset_train_val_test['val'][i]['text2'])\n",
    "\n",
    "val_dataset = []\n",
    "no_of_positive_pairs = 0\n",
    "no_of_negative_pairs = 0\n",
    "\n",
    "for i, (q_i, tool_description_i) in enumerate(zip(queries, tool_descriptions)):\n",
    "    if random.random() < 0.5:\n",
    "        label = 1\n",
    "        tool_description = tool_description_i\n",
    "        no_of_positive_pairs += 1\n",
    "    else:\n",
    "        label = 0\n",
    "        tool_description = random.choice(list(set(all_tool_descriptions) - {tool_description_i}))\n",
    "        no_of_negative_pairs += 1\n",
    "\n",
    "    data = {\n",
    "        \"text1\": q_i,\n",
    "        \"text2\": tool_description,\n",
    "        \"label\": label\n",
    "    }\n",
    "    val_dataset.append(data)\n",
    "\n",
    "print(no_of_positive_pairs, no_of_negative_pairs)\n",
    "\n",
    "queries = []\n",
    "tool_descriptions = []\n",
    "for i in range(len(dataset_train_val_test['test'])):\n",
    "    queries.append(dataset_train_val_test['test'][i]['text1'])\n",
    "    tool_descriptions.append(dataset_train_val_test['test'][i]['text2'])\n",
    "    \n",
    "\n",
    "test_dataset = []\n",
    "\n",
    "no_of_positive_pairs = 0\n",
    "no_of_negative_pairs = 0\n",
    "\n",
    "for i, (q_i, tool_description_i) in enumerate(zip(queries, tool_descriptions)):\n",
    "    if random.random() < 0.5:\n",
    "        label = 1\n",
    "        tool_description = tool_description_i\n",
    "        no_of_positive_pairs += 1\n",
    "    else:\n",
    "        label = 0\n",
    "        tool_description = random.choice(list(set(all_tool_descriptions) - {tool_description_i}))\n",
    "        no_of_negative_pairs += 1\n",
    "\n",
    "    data = {\n",
    "        \"text1\": q_i,\n",
    "        \"text2\": tool_description,\n",
    "        \"label\": label\n",
    "    }\n",
    "    test_dataset.append(data)\n",
    "\n",
    "print(no_of_positive_pairs, no_of_negative_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96008ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 658892/658892 [00:00<00:00, 1870242.23 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 73211/73211 [00:00<00:00, 1216024.10 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 81345/81345 [00:00<00:00, 1025585.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": dataset_train_val_test['train'],\n",
    "    \"val\": Dataset.from_list(val_dataset),\n",
    "    \"test\": Dataset.from_list(test_dataset)\n",
    "})\n",
    "\n",
    "dataset_dict.save_to_disk(\"../data/positive_pairs_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30ab5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_dict = load_from_disk(\"../data/positive_pairs_v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dd1ec22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text1', 'text2', 'label'],\n",
       "    num_rows: 81345\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36c2ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = [x['text1'] for x in dataset_dict['test']]\n",
    "all_queries_set = set(all_queries)\n",
    "\n",
    "data_df['test'] = data_df['query'].apply(lambda x: x in all_queries_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5b1b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_test = data_df[data_df['test'] == True]\n",
    "import random\n",
    "\n",
    "# Shuffle the test dataframe and select 500 examples\n",
    "data_df_test_shuffled = data_df_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "data_df_test_500 = data_df_test_shuffled.head(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20126254",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_json = []\n",
    "\n",
    "for i, row in data_df_test_500.iterrows():\n",
    "    row_dict = {\n",
    "        \"query\": row['query'],\n",
    "        \"tools\": row['tools_required'],\n",
    "    }\n",
    "    if 'reply' in row['tools_required']:\n",
    "        row_dict['decision'] = 'integrations'\n",
    "        # print(f'Query: {row[\"query\"]}')\n",
    "        # print(f'Reply: {row[\"tools_required\"]}')\n",
    "        row_dict['tools'].append('send_message')\n",
    "    elif 'unachievable_task' in row['tools_required']:\n",
    "        row_dict['decision'] = 'unachievable'\n",
    "        row_dict['tools'] = []\n",
    "        # print(f'Query: {row[\"query\"]}')\n",
    "        # print(f'Unachievable: {row[\"tools_required\"]}')\n",
    "    else:\n",
    "        row_dict['decision'] = 'integrations'\n",
    "    integrations = []\n",
    "    for tool in row['tools_required']:\n",
    "        tool = tool.split('-')[0].split(' ')[0]\n",
    "        if tool in tools_to_integration_map:\n",
    "            integrations.append(tools_to_integration_map[tool])\n",
    "        else:\n",
    "            if 'Slack' in tool:\n",
    "                integrations.append('Slack')\n",
    "            elif 'message' in tool:\n",
    "                integrations.append('Messages')\n",
    "            else:\n",
    "                print(f'Tool not found: {tool}')\n",
    "\n",
    "    row_dict['tools'] = list(set(row_dict['tools']))\n",
    "    row_dict['integrations'] = list(set(integrations))\n",
    "    evals_json.append(row_dict)\n",
    "\n",
    "with open(\"../data/evals_test_500_v1.json\", \"w\") as f:\n",
    "    json.dump(evals_json, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
